Executing GAN training run defined in ../config_files/train/gan/weird_gan__tinyaes_b ...
Settings:
	save_dir: weird_gan__tinyaes_b
	dataset_name: GoogleTinyAES
	dataset_kwargs: {'target_byte': 7, 'interval_to_use': [0, 20000], 'target_attack_point': 'sub_bytes_out'}
	discriminator_name: DCGAN__Discriminator
	discriminator_kwargs: {'use_sn': True, 'num_blocks': 6}
	generator_name: DCGAN__Generator
	discriminator_optimizer_class: Adam
	discriminator_optimizer_kwargs: {'lr': 0.0004, 'betas': [0.5, 0.999]}
	generator_optimizer_class: Adam
	generator_optimizer_kwargs: {'lr': 0.0001, 'betas': [0.5, 0.999]}
	train_sample_transforms: ['ToFloatTensor', ['Downsample', {'downsample_ratio': 4}], ['Normalize', {'min': -1.026, 'max': 0.9854}]]
	train_target_transforms: ['ToLongTensor']
	eval_sample_transforms: ['ToFloatTensor', ['Downsample', {'downsample_ratio': 4}], ['Normalize', {'min': -1.026, 'max': 0.9854}]]
	eval_target_transforms: ['ToLongTensor']
	disc_steps_per_gen_step: 1.0
	pert_l1_decay: 0.01
	cal_temperature: False
	pretrain_epochs: 5
	total_epochs: 100
	seed: 0
	batch_size: 32
	val_split_prop: 0.2
Warning: unused kwargs with names 'save_dir', 'total_epochs'
Initializing trial ...
Results save directory: ../results/weird_gan__tinyaes_b/trial_2/results
Model save directory: ../results/weird_gan__tinyaes_b/trial_2/models
Generator:
DCGAN__Generator(
  (downsample_blocks): ModuleList(
    (0): Sequential(
      (0): Conv1d(1, 16, kernel_size=(11,), stride=(2,), padding=(5,))
      (1): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv1d(16, 32, kernel_size=(11,), stride=(2,), padding=(5,))
      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv1d(32, 64, kernel_size=(11,), stride=(2,), padding=(5,))
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (upsample_blocks): ModuleList(
    (0): Sequential(
      (0): Upsample(scale_factor=2.0, mode='nearest')
      (1): Conv1d(64, 32, kernel_size=(11,), stride=(1,), padding=(5,))
      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Upsample(scale_factor=2.0, mode='nearest')
      (1): Conv1d(64, 16, kernel_size=(11,), stride=(1,), padding=(5,))
      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Upsample(scale_factor=2.0, mode='nearest')
      (1): Conv1d(32, 1, kernel_size=(11,), stride=(1,), padding=(5,))
      (2): ReLU(inplace=True)
    )
  )
)
Discriminator:
DCGAN__Discriminator(
  	Rescaling temperature to 1.7014132738113403.
  (feature_extractor): Sequential(
    (0): Sequential(
      (0): ParametrizedConv1d(
        1, 16, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
    )
    (1): Sequential(
      (0): ParametrizedConv1d(
        16, 32, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): ParametrizedConv1d(
        32, 64, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): Sequential(
      (0): ParametrizedConv1d(
        64, 128, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): Sequential(
      (0): ParametrizedConv1d(
        128, 256, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): Sequential(
      (0): ParametrizedConv1d(
        256, 512, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): AdaptiveAvgPool1d(output_size=1)
    (7): Flatten(start_dim=1, end_dim=-1)
  )
  (head): ParametrizedLinear(
    in_features=512, out_features=256, bias=True
    (parametrizations): ModuleDict(
      (weight): ParametrizationList(
        (0): _SpectralNorm()
      )
    )
  )
)
Train dataset: Google_TinyAES(length=65536, data_shape=(1, 20000), train=True, transform=Compose(
    ToFloatTensor()
    Downsample(downsample_ratio=4)
    Normalize(min=-1.026, max=0.9854)
), target_transform=Compose(
    ToLongTensor()
))
Val dataset: Google_TinyAES(length=65536, data_shape=(1, 20000), train=True, transform=Compose(
    ToFloatTensor()
    Downsample(downsample_ratio=4)
    Normalize(min=-1.026, max=0.9854)
), target_transform=Compose(
    ToLongTensor()
))
Test dataset: Google_TinyAES(length=65536, data_shape=(1, 20000), train=False, transform=Compose(
    ToFloatTensor()
    Downsample(downsample_ratio=4)
    Normalize(min=-1.026, max=0.9854)
), target_transform=Compose(
    ToLongTensor()
))
Train/val lengths: 52429 / 13107
Train/val/test dataloaders: DataLoader(batch_size=32, shuffle=True, num_workers=12, pin_memory=True) / DataLoader(batch_size=32, shuffle=False, num_workers=12, pin_memory=True) / DataLoader(batch_size=32, shuffle=False, num_workers=12, pin_memory=True)
Gen/disc optimizers: Adam (
Parameter Group 0
    amsgrad: False
    betas: [0.5, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
) / Adam (
Parameter Group 0
    amsgrad: False
    betas: [0.5, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0
)
Device: cuda:2
Seed: 0
Starting pretraining.

Starting epoch -5 ...
Training results:
	msec_per_batch: 31.36325311922605
	d_temp: 1.7014132738113403
	d_train_loss: 4.663322676530038
	d_train_acc: 0.07266097995963768
	gen_train_loss: 0.006285677489770257
Validation results:
	msec_per_batch: 11.357030801075261
	d_temp: 1.7014132738113403
	d_train_loss: 4.535039980818586
	d_train_acc: 0.12833360077021821
	d_cal_ece: 0.11270329232622937
	perturbation_l1_loss: 3.320866790368089e-06
	perturbation_confusion_loss: 5.653615670087861
Test results:
	msec_per_batch: 11.006552998907864
	d_temp: 1.7014132738113403
	d_train_loss: 4.532905254745856
	d_train_acc: 0.1323089599609375
	d_cal_ece: 0.11623462095531067
	perturbation_l1_loss: 3.4141042334345784e-06
	perturbation_confusion_loss: 5.653344525722787

Starting epoch -4 ...
Training results:
	msec_per_batch: 28.11929655860589
	d_temp: 1.7014132738113403
	d_train_loss: 3.67254366592491
	d_train_acc: 0.15971863706763037
	gen_train_loss: 1.5566198653915507e-06
Validation results:
	msec_per_batch: 11.389213721345111
	d_temp: 1.7014132738113403
	d_train_loss: 3.9309064632508814
	d_train_acc: 0.21878209242618743
	d_cal_ece: 0.18563234078266272
	perturbation_l1_loss: 6.388883304733682e-07
	perturbation_confusion_loss: 5.803619655748693
Test results:
	msec_per_batch: 11.133294481085613
	d_temp: 1.7014132738113403
	d_train_loss: 3.931636984925717
	d_train_acc: 0.2265472412109375
	d_cal_ece: 0.19360117616179195
	perturbation_l1_loss: 6.535262467798923e-07
	perturbation_confusion_loss: 5.801757444394752

Starting epoch -3 ...
Training results:
	msec_per_batch: 28.975149420574716
	d_temp: 1.7014132738113403
	d_train_loss: 2.9363548693095423
	d_train_acc: 0.2877003449570564
	gen_train_loss: 3.597450442066658e-07
Validation results:
	msec_per_batch: 11.702863836288453
	d_temp: 1.7014132738113403
	d_train_loss: 3.222998455675637
	d_train_acc: 0.3244022785622593
	d_cal_ece: 0.25438102489201037
	perturbation_l1_loss: 1.9342472575648773e-07
	perturbation_confusion_loss: 6.07932050635175
Test results:
	msec_per_batch: 11.546423122985289
	d_temp: 1.7014132738113403
	d_train_loss: 3.22043206973467
	d_train_acc: 0.323211669921875
	d_cal_ece: 0.25261563555250177
	perturbation_l1_loss: 2.0588507075552486e-07
	perturbation_confusion_loss: 6.082326512085274

Starting epoch -2 ...
Training results:
	msec_per_batch: 29.43689114266303
	d_temp: 1.7014132738113403
	d_train_loss: 2.4364831868725045
	d_train_acc: 0.35525296850800203
	gen_train_loss: 1.1020011381523236e-07
Validation results:
	msec_per_batch: 11.31389564304817
	d_temp: 1.7014132738113403
	d_train_loss: 3.0388263318596818
	d_train_acc: 0.34726813222079583
	d_cal_ece: 0.2553409092037416
	perturbation_l1_loss: 7.002386387995979e-08
	perturbation_confusion_loss: 6.199582929145999
Test results:
	msec_per_batch: 11.606598480604589
	d_temp: 1.7014132738113403
	d_train_loss: 3.0357902734540403
	d_train_acc: 0.34661865234375
	d_cal_ece: 0.2554672406640748
	perturbation_l1_loss: 8.391610769211257e-08
	perturbation_confusion_loss: 6.199688462074846

Starting epoch -1 ...
Training results:
	msec_per_batch: 28.152616559040844
	d_temp: 1.7014132738113403
	d_train_loss: 2.1694854776476706
	d_train_acc: 0.3881910874360539
	gen_train_loss: 3.6647127843499445e-08
Validation results:
	msec_per_batch: 11.554032390873607
	d_temp: 1.7014132738113403
	d_train_loss: 2.7204327333264233
	d_train_acc: 0.3761553273427471
	d_cal_ece: 0.2592316556994508
	perturbation_l1_loss: 2.641183960157109e-08
	perturbation_confusion_loss: 6.462844170593634
Test results:
	msec_per_batch: 11.727187061682343
	d_temp: 1.7014132738113403
	d_train_loss: 2.7155651431530714
	d_train_acc: 0.381561279296875
	d_cal_ece: 0.2651327211788157
	perturbation_l1_loss: 3.617049044950097e-08
	perturbation_confusion_loss: 6.46368521079421
Starting training.

Starting epoch 0 ...
Training results:
	msec_per_batch: 8143.357580961142
	d_temp: 1.7014132738113403
	d_train_loss: 2.269443216885351
	d_train_acc: 0.36510448444173277
	perturbation_steps: 10.0
	perturbation_dist: 3254.4520600496667
	gen_train_loss: 0.5989516631376494
Validation results:
	msec_per_batch: 17.881837274970078
	d_temp: 1.7014132738113403
	d_train_loss: 6.053574014291531
	d_train_acc: 0.052110077021822854
	d_cal_ece: 0.2852519529258333
	perturbation_l1_loss: 0.01864705079394143
	perturbation_confusion_loss: 10.60810886941305
Test results:
	msec_per_batch: 17.325142082292587
	d_temp: 1.7014132738113403
	d_train_loss: 6.081871972884983
	d_train_acc: 0.052520751953125
	d_cal_ece: 0.2880889632724575
	perturbation_l1_loss: 0.018640522337591392
	perturbation_confusion_loss: 10.650889629032463

Starting epoch 1 ...
Training results:
	msec_per_batch: 8154.236162782661
	d_temp: 1.7014132738113403
	d_train_loss: 3.5342114409562506
	d_train_acc: 0.1492716595485052
	perturbation_steps: 10.0
	perturbation_dist: 21.988426366108374
	gen_train_loss: 0.018288661136568646
Validation results:
	msec_per_batch: 16.61320857536502
	d_temp: 1.7014132738113403
	d_train_loss: 4.68887355443908
	d_train_acc: 0.06687259306803595
	d_cal_ece: 0.1516563845298639
	perturbation_l1_loss: 0.05592389898147525
	perturbation_confusion_loss: 9.457891748009658
Test results:
	msec_per_batch: 16.44657230656594
	d_temp: 1.7014132738113403
	d_train_loss: 4.707477725576609
	d_train_acc: 0.06427001953125
	d_cal_ece: 0.15481875258046784
	perturbation_l1_loss: 0.055961736497920356
	perturbation_confusion_loss: 9.456480225780979

Starting epoch 2 ...
Training results:
	msec_per_batch: 8124.945055102196
	d_temp: 1.7014132738113403
	d_train_loss: 4.304734534647059
	d_train_acc: 0.06339612568639415
	perturbation_steps: 10.0
	perturbation_dist: 70.69928769013589
	gen_train_loss: 0.031505312610791494
Validation results:
	msec_per_batch: 14.165179393349625
	d_temp: 1.7014132738113403
	d_train_loss: 6.09240766153103
	d_train_acc: 0.0037347560975609755
	d_cal_ece: 0.02416056691237339
	perturbation_l1_loss: 0.0336556203027324
	perturbation_confusion_loss: 6.152731864045306
Test results:
	msec_per_batch: 13.976600387366489
	d_temp: 1.7014132738113403
	d_train_loss: 6.0944869762752205
	d_train_acc: 0.0039215087890625
	d_cal_ece: 0.02391188750971196
	perturbation_l1_loss: 0.03368346427305369
	perturbation_confusion_loss: 6.152941385051236

Starting epoch 3 ...
Training results:
	msec_per_batch: 8112.8750131082215
	d_temp: 1.7014132738113403
	d_train_loss: 3.902824405055718
	d_train_acc: 0.09433079504388231
	perturbation_steps: 10.0
	perturbation_dist: 32.17181882027666
	gen_train_loss: 0.020133766605856286
Validation results:
	msec_per_batch: 14.429221467273992
	d_temp: 1.7014132738113403
	d_train_loss: 5.234565275471385
	d_train_acc: 0.013338414634146341
	d_cal_ece: 0.039619790620692985
	perturbation_l1_loss: 0.06442160088478065
	perturbation_confusion_loss: 6.703568816766507
Test results:
	msec_per_batch: 13.888617971679196
	d_temp: 1.7014132738113403
	d_train_loss: 5.221179271349683
	d_train_acc: 0.0159759521484375
	d_cal_ece: 0.03915488647442089
	perturbation_l1_loss: 0.06443532200501068
	perturbation_confusion_loss: 6.698661930393428

Starting epoch 4 ...
Training results:
	msec_per_batch: 8103.489076084884
	d_temp: 1.7014132738113403
	d_train_loss: 3.915834918409095
	d_train_acc: 0.08997336556061389
	perturbation_steps: 10.0
	perturbation_dist: 740.7531809536985
	gen_train_loss: 0.17929432511825713
Validation results:
	msec_per_batch: 16.02130927109137
	d_temp: 1.7014132738113403
	d_train_loss: 7.4552803667580205
	d_train_acc: 0.02301829268292683
	d_cal_ece: 0.17423272699844547
	perturbation_l1_loss: 0.05451573907602124
	perturbation_confusion_loss: 10.857447161325593
Test results:
	msec_per_batch: 16.19742395961657
	d_temp: 1.7014132738113403
	d_train_loss: 7.439406319288537
	d_train_acc: 0.020172119140625
	d_cal_ece: 0.17710103788704146
	perturbation_l1_loss: 0.054574507110373816
	perturbation_confusion_loss: 10.854532167781144

Starting epoch 5 ...
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe7a46c7940>
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1423, in _shutdown_workers
    self._worker_result_queue.put((None, None))
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/queues.py", line 94, in put
    self._start_thread()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/queues.py", line 177, in _start_thread
    self._thread.start()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 904, in start
    self._started.wait()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 43108) is killed by signal: Terminated. 
