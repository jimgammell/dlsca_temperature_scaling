Executing GAN training run defined in ../config_files/train/gan/weird_gan__tinyaes_e ...
Settings:
	save_dir: weird_gan__tinyaes_e
	dataset_name: GoogleTinyAES
	dataset_kwargs: {'target_byte': 7, 'interval_to_use': [0, 20000], 'target_attack_point': 'sub_bytes_out'}
	discriminator_name: DCGAN__Discriminator
	discriminator_kwargs: {'use_sn': True, 'num_blocks': 6}
	generator_name: DCGAN__Generator
	discriminator_optimizer_class: Adam
	discriminator_optimizer_kwargs: {'lr': 0.0004, 'betas': [0.5, 0.999]}
	generator_optimizer_class: Adam
	generator_optimizer_kwargs: {'lr': 0.0001, 'betas': [0.5, 0.999]}
	train_sample_transforms: ['ToFloatTensor', ['Downsample', {'downsample_ratio': 4}], ['Normalize', {'min': -1.026, 'max': 0.9854}]]
	train_target_transforms: ['ToLongTensor']
	eval_sample_transforms: ['ToFloatTensor', ['Downsample', {'downsample_ratio': 4}], ['Normalize', {'min': -1.026, 'max': 0.9854}]]
	eval_target_transforms: ['ToLongTensor']
	disc_steps_per_gen_step: 1.0
	pert_l1_decay: 0.01
	cal_temperature: False
	pretrain_epochs: 5
	total_epochs: 100
	seed: 0
	batch_size: 32
	val_split_prop: 0.2
Warning: unused kwargs with names 'save_dir', 'total_epochs'
Initializing trial ...
Results save directory: ../results/weird_gan__tinyaes_e/trial_0/results
Model save directory: ../results/weird_gan__tinyaes_e/trial_0/models
Generator:
DCGAN__Generator(
  (downsample_blocks): ModuleList(
    (0): Sequential(
      (0): Conv1d(1, 16, kernel_size=(11,), stride=(2,), padding=(5,))
      (1): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv1d(16, 32, kernel_size=(11,), stride=(2,), padding=(5,))
      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv1d(32, 64, kernel_size=(11,), stride=(2,), padding=(5,))
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (upsample_blocks): ModuleList(
    (0): Sequential(
      (0): Upsample(scale_factor=2.0, mode='nearest')
      (1): Conv1d(64, 32, kernel_size=(11,), stride=(1,), padding=(5,))
      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Upsample(scale_factor=2.0, mode='nearest')
      (1): Conv1d(64, 16, kernel_size=(11,), stride=(1,), padding=(5,))
      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Upsample(scale_factor=2.0, mode='nearest')
      (1): Conv1d(32, 1, kernel_size=(11,), stride=(1,), padding=(5,))
      (2): ReLU(inplace=True)
    )
  )
)
Discriminator:
DCGAN__Discriminator(
  	Rescaling temperature to 1.7014132738113403.
  (feature_extractor): Sequential(
    (0): Sequential(
      (0): ParametrizedConv1d(
        1, 16, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
    )
    (1): Sequential(
      (0): ParametrizedConv1d(
        16, 32, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Sequential(
      (0): ParametrizedConv1d(
        32, 64, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): Sequential(
      (0): ParametrizedConv1d(
        64, 128, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): Sequential(
      (0): ParametrizedConv1d(
        128, 256, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): Sequential(
      (0): ParametrizedConv1d(
        256, 512, kernel_size=(11,), stride=(2,), padding=(5,)
        (parametrizations): ModuleDict(
          (weight): ParametrizationList(
            (0): _SpectralNorm()
          )
        )
      )
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): AdaptiveAvgPool1d(output_size=1)
    (7): Flatten(start_dim=1, end_dim=-1)
  )
  (head): ParametrizedLinear(
    in_features=512, out_features=256, bias=True
    (parametrizations): ModuleDict(
      (weight): ParametrizationList(
        (0): _SpectralNorm()
      )
    )
  )
)
Train dataset: Google_TinyAES(length=65536, data_shape=(1, 20000), train=True, transform=Compose(
    ToFloatTensor()
    Downsample(downsample_ratio=4)
    Normalize(min=-1.026, max=0.9854)
), target_transform=Compose(
    ToLongTensor()
))
Val dataset: Google_TinyAES(length=65536, data_shape=(1, 20000), train=True, transform=Compose(
    ToFloatTensor()
    Downsample(downsample_ratio=4)
    Normalize(min=-1.026, max=0.9854)
), target_transform=Compose(
    ToLongTensor()
))
Test dataset: Google_TinyAES(length=65536, data_shape=(1, 20000), train=False, transform=Compose(
    ToFloatTensor()
    Downsample(downsample_ratio=4)
    Normalize(min=-1.026, max=0.9854)
), target_transform=Compose(
    ToLongTensor()
))
Train/val lengths: 52429 / 13107
Train/val/test dataloaders: DataLoader(batch_size=32, shuffle=True, num_workers=12, pin_memory=True) / DataLoader(batch_size=32, shuffle=False, num_workers=12, pin_memory=True) / DataLoader(batch_size=32, shuffle=False, num_workers=12, pin_memory=True)
Gen/disc optimizers: Adam (
Parameter Group 0
    amsgrad: False
    betas: [0.5, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
) / Adam (
Parameter Group 0
    amsgrad: False
    betas: [0.5, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0
)
Device: cuda:2
Seed: 0
Starting pretraining.

Starting epoch -5 ...
Training results:
	msec_per_batch: 26.176128610886764
	d_temp: 1.7014132738113403
	d_train_loss: 4.669890978483255
	d_train_acc: 0.07066926362228376
	gen_train_loss: 0.006285511840795878
Validation results:
	msec_per_batch: 16.93038384972549
	d_temp: 1.7014132738113403
	d_train_loss: 4.526079416275024
	d_train_acc: 0.13067233632862643
	d_cal_ece: 0.11499489308221311
	perturbation_l1_loss: 3.3061923192035907e-06
	perturbation_confusion_loss: 5.655001236752766
Test results:
	msec_per_batch: 14.781254028202966
	d_temp: 1.7014132738113403
	d_train_loss: 4.523360159946606
	d_train_acc: 0.1339569091796875
	d_cal_ece: 0.11758330335851497
	perturbation_l1_loss: 3.398926978565031e-06
	perturbation_confusion_loss: 5.654861823888496

Starting epoch -4 ...
Training results:
	msec_per_batch: 24.252547298429068
	d_temp: 1.7014132738113403
	d_train_loss: 3.6504527450407913
	d_train_acc: 0.1705293448162576
	gen_train_loss: 1.5541685515009487e-06
Validation results:
	msec_per_batch: 16.310896482700254
	d_temp: 1.7014132738113403
	d_train_loss: 3.7642355476937643
	d_train_acc: 0.25267570603337614
	d_cal_ece: 0.21234485892260946
	perturbation_l1_loss: 6.379318201815292e-07
	perturbation_confusion_loss: 5.858218054655121
Test results:
	msec_per_batch: 15.51595050166361
	d_temp: 1.7014132738113403
	d_train_loss: 3.763672062312253
	d_train_acc: 0.25897216796875
	d_cal_ece: 0.21895364293686725
	perturbation_l1_loss: 6.525623901981791e-07
	perturbation_confusion_loss: 5.856218760367483

Starting epoch -3 ...
Training results:
	msec_per_batch: 24.807452101762735
	d_temp: 1.7014132738113403
	d_train_loss: 2.8788848001830383
	d_train_acc: 0.30176115830478245
	gen_train_loss: 3.5932696534463005e-07
Validation results:
	msec_per_batch: 15.878735835377762
	d_temp: 1.7014132738113403
	d_train_loss: 3.3510170006170505
	d_train_acc: 0.340737323491656
	d_cal_ece: 0.28191873495716874
	perturbation_l1_loss: 1.944349235351001e-07
	perturbation_confusion_loss: 5.952553380407938
Test results:
	msec_per_batch: 14.866987510817125
	d_temp: 1.7014132738113403
	d_train_loss: 3.3495224530342966
	d_train_acc: 0.342742919921875
	d_cal_ece: 0.28380321987060597
	perturbation_l1_loss: 2.0670815281624414e-07
	perturbation_confusion_loss: 5.953619768610224

Starting epoch -2 ...
Training results:
	msec_per_batch: 24.205188467271302
	d_temp: 1.7014132738113403
	d_train_loss: 2.4244597579299714
	d_train_acc: 0.35817894353968177
	gen_train_loss: 1.1107268555601658e-07
Validation results:
	msec_per_batch: 16.340732154613587
	d_temp: 1.7014132738113403
	d_train_loss: 3.17291064785748
	d_train_acc: 0.2929717586649551
	d_cal_ece: 0.20688096376635678
	perturbation_l1_loss: 7.140435273164726e-08
	perturbation_confusion_loss: 6.204158815523473
Test results:
	msec_per_batch: 16.63704802794382
	d_temp: 1.7014132738113403
	d_train_loss: 3.1695012780837715
	d_train_acc: 0.2932281494140625
	d_cal_ece: 0.208120440127459
	perturbation_l1_loss: 8.480639429224386e-08
	perturbation_confusion_loss: 6.203953170217574

Starting epoch -1 ...
Training results:
	msec_per_batch: 24.702449802075165
	d_temp: 1.7014132738113403
	d_train_loss: 2.1717450127796547
	d_train_acc: 0.3879344229595908
	gen_train_loss: 3.642068201278358e-08
Validation results:
	msec_per_batch: 17.04104334668415
	d_temp: 1.7014132738113403
	d_train_loss: 2.788180059339942
	d_train_acc: 0.3894937419768934
	d_cal_ece: 0.28113636107343
	perturbation_l1_loss: 2.9347407111243797e-08
	perturbation_confusion_loss: 6.343831253051758
Test results:
	msec_per_batch: 16.221069485647604
	d_temp: 1.7014132738113403
	d_train_loss: 2.7792525235563517
	d_train_acc: 0.3975830078125
	d_cal_ece: 0.28779328497694223
	perturbation_l1_loss: 3.605574355066251e-08
	perturbation_confusion_loss: 6.34547641640529
Starting training.

Starting epoch 0 ...
Training results:
	msec_per_batch: 8203.369007159472
	d_temp: 1.7014132738113403
	d_train_loss: 2.4647656383130374
	d_train_acc: 0.3343296803867274
	perturbation_steps: 10.0
	perturbation_dist: 36.85241336470482
	gen_train_loss: 0.03200735528018642
Validation results:
	msec_per_batch: 15.729776361511975
	d_temp: 1.7014132738113403
	d_train_loss: 4.362897192559591
	d_train_acc: 0.07119303594351734
	d_cal_ece: 0.11395426064547969
	perturbation_l1_loss: 0.07058143143246813
	perturbation_confusion_loss: 7.509946490497124
Test results:
	msec_per_batch: 15.928219406865537
	d_temp: 1.7014132738113403
	d_train_loss: 4.378557035000995
	d_train_acc: 0.0703125
	d_cal_ece: 0.11503511737464578
	perturbation_l1_loss: 0.07061440887264325
	perturbation_confusion_loss: 7.519452881067991

Starting epoch 1 ...
Training results:
	msec_per_batch: 8188.7679219179
	d_temp: 1.7014132738113403
	d_train_loss: 4.209211609434834
	d_train_acc: 0.07214765100671142
	perturbation_steps: 10.0
	perturbation_dist: 28.504598366115935
	gen_train_loss: 0.016976339000438028
Validation results:
	msec_per_batch: 15.794253598189936
	d_temp: 1.7014132738113403
	d_train_loss: 5.1312729277261875
	d_train_acc: 0.04258263799743261
	d_cal_ece: 0.10687726021903317
	perturbation_l1_loss: 0.06395026365431343
	perturbation_confusion_loss: 8.51867874424632
Test results:
	msec_per_batch: 15.431579985190183
	d_temp: 1.7014132738113403
	d_train_loss: 5.139051564503461
	d_train_acc: 0.0419464111328125
	d_cal_ece: 0.10550776877062162
	perturbation_l1_loss: 0.06397179461600899
	perturbation_confusion_loss: 8.52256703726016

Starting epoch 2 ...
Training results:
	msec_per_batch: 8172.044068351033
	d_temp: 1.7014132738113403
	d_train_loss: 3.6015338035092404
	d_train_acc: 0.11237797437461867
	perturbation_steps: 10.0
	perturbation_dist: 188.7078139157176
	gen_train_loss: 0.08140873856932866
Validation results:
	msec_per_batch: 16.185930761476843
	d_temp: 1.7014132738113403
	d_train_loss: 4.41815672095229
	d_train_acc: 0.060674743260590504
	d_cal_ece: 0.11968913141910623
	perturbation_l1_loss: 0.04684404738065673
	perturbation_confusion_loss: 9.233950545148153
Test results:
	msec_per_batch: 16.20303601678461
	d_temp: 1.7014132738113403
	d_train_loss: 4.409199759829789
	d_train_acc: 0.061981201171875
	d_cal_ece: 0.11938363774333993
	perturbation_l1_loss: 0.04687394512075116
	perturbation_confusion_loss: 9.214678368996829

Starting epoch 3 ...
Training results:
	msec_per_batch: 8175.653241365257
	d_temp: 1.7014132738113403
	d_train_loss: 3.865497902444836
	d_train_acc: 0.08702832402496834
	perturbation_steps: 10.0
	perturbation_dist: 251.50793875434763
	gen_train_loss: 0.09688821432616532
Validation results:
	msec_per_batch: 16.003309128924116
	d_temp: 1.7014132738113403
	d_train_loss: 5.491693710699314
	d_train_acc: 0.02368019897304236
	d_cal_ece: 0.1259615914214675
	perturbation_l1_loss: 0.07446159696797046
	perturbation_confusion_loss: 8.769947626532577
Test results:
	msec_per_batch: 16.027755495160818
	d_temp: 1.7014132738113403
	d_train_loss: 5.483443864155561
	d_train_acc: 0.0248870849609375
	d_cal_ece: 0.1278151892565802
	perturbation_l1_loss: 0.07449581028413377
	perturbation_confusion_loss: 8.779904275201261

Starting epoch 4 ...
Training results:
	msec_per_batch: 8199.095743641321
	d_temp: 1.7014132738113403
	d_train_loss: 3.610441639773943
	d_train_acc: 0.12157536255690618
	perturbation_steps: 10.0
	perturbation_dist: 52.24274590140512
	gen_train_loss: 0.03341990023157591
Validation results:
	msec_per_batch: 16.86754007572081
	d_temp: 1.7014132738113403
	d_train_loss: 4.361763780291487
	d_train_acc: 0.07246068677792042
	d_cal_ece: 0.14635675881148838
	perturbation_l1_loss: 0.12060204053797373
	perturbation_confusion_loss: 9.213905755484976
Test results:
	msec_per_batch: 16.59912849823013
	d_temp: 1.7014132738113403
	d_train_loss: 4.3611863277619705
	d_train_acc: 0.07598876953125
	d_cal_ece: 0.14505156212726433
	perturbation_l1_loss: 0.12064649666353944
	perturbation_confusion_loss: 9.190416730940342

Starting epoch 5 ...
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7faf88038940>
Traceback (most recent call last):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1442, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/min/a/jgammell/miniconda3/envs/sca-defense/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 45649) is killed by signal: Terminated. 
